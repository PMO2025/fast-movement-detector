{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3641d5a8-1f91-4266-9540-2a3346163445",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import Video, Image, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3012348c-a47c-4c1d-8cc3-8bffdbd8b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"./sources/test4.mov\"\n",
    "proc_width, proc_height = 640, 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d43d76e-843e-4982-8077-48b316221c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(path, width, height):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        succ, frame = cap.read()\n",
    "        if not succ:\n",
    "            break\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (width, height))\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return np.stack(frames, axis=0), fps\n",
    "\n",
    "\n",
    "def write_video(path, frames, fps, codec=\"vp80\"):\n",
    "    if type(frames) != np.array:\n",
    "        frames = np.stack(frames, axis=0)\n",
    "\n",
    "    frames = frames.astype(np.uint8)\n",
    "\n",
    "    _, height, width, _ = frames.shape\n",
    "    out = cv2.VideoWriter(path, cv2.VideoWriter_fourcc(\n",
    "        *codec), fps, (width, height))\n",
    "    for frame in frames:\n",
    "        out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    out.release()\n",
    "\n",
    "\n",
    "def display_video(frames, fps):\n",
    "    path = \"./outputs/display.webm\"\n",
    "    write_video(path, frames, fps)\n",
    "    # clear_output(wait=True)\n",
    "    display(Video(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b040c5d-0a34-4e7c-9155-96606f0c8904",
   "metadata": {},
   "source": [
    "### Load YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be450ab4-6d73-43ed-8e4a-ae87487d166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "os.environ[\"YOLO_VERBOSE\"] = \"False\"\n",
    "\n",
    "\n",
    "yolo_model = YOLO(\"yolo/yolo11n-seg.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2f395-6baa-4149-aafd-ad1b9a8d7223",
   "metadata": {},
   "source": [
    "### Load VDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83dd4a0c-0cd0-44a3-bfce-2033a662fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vda.video_depth_anything.video_depth import VideoDepthAnything\n",
    "from vda.utils.dc_utils import save_video\n",
    "\n",
    "config = {\"encoder\": \"vits\", \"features\": 64,\n",
    "          \"out_channels\": [48, 96, 192, 384]}\n",
    "vda_model = VideoDepthAnything(**config)\n",
    "vda_model.load_state_dict(torch.load(\n",
    "    f\"./vda/checkpoints/video_depth_anything_vits.pth\", map_location=\"cpu\"), strict=True)\n",
    "vda_model = vda_model.to(DEVICE).eval()\n",
    "\n",
    "vda_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d241e78-a220-41d1-ac39-70027c0dcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpFilter:\n",
    "    def __init__(self, gain: float):\n",
    "        self.state = None\n",
    "        self.gain = gain\n",
    "\n",
    "    def push(self, x):\n",
    "        if self.state is None:\n",
    "            self.state = x\n",
    "        else:\n",
    "            self.state = self.gain * x + (1 - self.gain) * self.state\n",
    "\n",
    "    def get(self):\n",
    "        return self.state\n",
    "\n",
    "\n",
    "def fmt_number(number, digits=3):\n",
    "    return str(int(number * (10**digits)) / (10**digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782dddd8-948b-4b8d-8312-bf338fdfa4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    if type(x) != np.array:\n",
    "        x = np.array(x)\n",
    "\n",
    "    return x / np.linalg.norm(x)\n",
    "\n",
    "\n",
    "def get_pixel_dir_1d(x, rx, fov):\n",
    "    px = math.sin(fov/2) * (2 * x / rx - 1)\n",
    "    py = math.cos(fov/2)\n",
    "    return normalize([px, py])\n",
    "\n",
    "\n",
    "def get_pixel_dir_2d(x, rx, hfov, y, ry, vfov):\n",
    "    hx, hy = get_pixel_dir_1d(x, rx, hfov)\n",
    "    vx, vy = get_pixel_dir_1d(y, ry, vfov)\n",
    "\n",
    "    return normalize([hx, vy, -vx])\n",
    "\n",
    "\n",
    "hfov = 73 / 180 * math.pi\n",
    "vfov = 2 * math.atan(math.tan(hfov/2)*(proc_height/proc_width))\n",
    "# print(hfov, vfov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "716b515a-a74b-4b35-b4f6-0aa87fcaaf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                             | 0/283.0 [00:00<?, ?it/s]\n",
      "\u001b[A%|                                                                                                                                                                                                                | 0/13 [00:00<?, ?it/s]\n",
      "\u001b[A%|███████████████▍                                                                                                                                                                                        | 1/13 [00:01<00:12,  1.07s/it]\n",
      "\u001b[A%|██████████████████████████████▊                                                                                                                                                                         | 2/13 [00:02<00:11,  1.02s/it]\n",
      "\u001b[A%|██████████████████████████████████████████████▏                                                                                                                                                         | 3/13 [00:03<00:10,  1.02s/it]\n",
      "\u001b[A%|█████████████████████████████████████████████████████████████▌                                                                                                                                          | 4/13 [00:04<00:09,  1.00s/it]\n",
      "\u001b[A%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                           | 5/13 [00:05<00:08,  1.00s/it]\n",
      "\u001b[A%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                           | 6/13 [00:06<00:06,  1.00it/s]\n",
      "\u001b[A%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 7/13 [00:07<00:05,  1.00it/s]\n",
      "\u001b[A%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                             | 8/13 [00:08<00:04,  1.01it/s]\n",
      "\u001b[A%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 9/13 [00:09<00:03,  1.00it/s]\n",
      "\u001b[A%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 10/13 [00:10<00:02,  1.01it/s]\n",
      "\u001b[A%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 11/13 [00:11<00:01,  1.01it/s]\n",
      "\u001b[A%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 12/13 [00:11<00:00,  1.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:12<00:00,  1.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 283/283.0 [00:26<00:00, 10.88it/s]\n",
      "OpenCV: FFMPEG: tag 0x30387076/'vp80' is not supported with codec id 139 and format 'webm / WebM'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/display.webm\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Iterator\n",
    "from itertools import tee\n",
    "\n",
    "VideoStream = Iterator[np.array]\n",
    "\n",
    "\n",
    "def create_video_stream(path: str, width: int, height: int) -> tuple[VideoStream, int]:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    def stream():\n",
    "        while cap.isOpened():\n",
    "            succ, frame = cap.read()\n",
    "            if not succ:\n",
    "                break\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, (width, height))\n",
    "            yield frame\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    return stream(), frames, fps\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SegObject:\n",
    "    tid: int\n",
    "    x: int\n",
    "    y: int\n",
    "    cx: int\n",
    "    cy: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cls: int\n",
    "    mask: np.array\n",
    "\n",
    "\n",
    "SegStream = Iterator[dict[int, SegObject]]\n",
    "\n",
    "\n",
    "def create_yolo_stream(video_stream: VideoStream) -> SegStream:\n",
    "    for frame in video_stream:\n",
    "        res = yolo_model.track(frame, persist=True)\n",
    "\n",
    "        tids = res[0].boxes.id.int().cpu().tolist()\n",
    "        boxes = res[0].boxes.data.cpu().tolist()\n",
    "        classes = res[0].boxes.cls.cpu().tolist()\n",
    "        masks = np.array(res[0].masks.data.cpu(), dtype=bool)\n",
    "\n",
    "        objects = {}\n",
    "        for tid, box, cls, mask in zip(tids, boxes, classes, masks):\n",
    "            x0, y0, x1, y1, *_ = box\n",
    "            objects[tid] = SegObject(\n",
    "                tid=int(tid),\n",
    "                x=int(x0),\n",
    "                y=int(y0),\n",
    "                cx=int((x0 + x1)/2),\n",
    "                cy=int((y0 + y1)/2),\n",
    "                width=int(x1 - x0),\n",
    "                height=int(y1 - y0),\n",
    "                cls=int(cls),\n",
    "                mask=mask,\n",
    "            )\n",
    "\n",
    "        yield objects\n",
    "\n",
    "\n",
    "DepthStream = Iterator[np.array]\n",
    "\n",
    "\n",
    "def create_vda_stream(video_stream: VideoStream, fps: int, *, cache=None) -> DepthStream:\n",
    "    if cache is None or cache not in vda_cache:\n",
    "        frames = np.array(list(video_stream))\n",
    "        depths, _ = vda_model.infer_video_depth(\n",
    "            frames, fps, input_size=518, device=DEVICE)\n",
    "        if cache is not None:\n",
    "            vda_cache[cache] = depths\n",
    "    else:\n",
    "        depths = vda_cache[cache]\n",
    "\n",
    "    for depth in depths:\n",
    "        depth = depth.max() - depth\n",
    "        depth = depth / depth.max()\n",
    "        yield depth\n",
    "\n",
    "\n",
    "AnchorStream = Iterator[int | None]\n",
    "\n",
    "\n",
    "def create_anchor_stream(seg_stream: SegStream, *, anchor_class: int, anchor_pos: tuple[int, int]) -> AnchorStream:\n",
    "    def find_anchor(objs: dict[int, SegObject]):\n",
    "        for tid, obj in objs.items():\n",
    "            if obj.cls == anchor_class and obj.mask[anchor_pos[1]][anchor_pos[0]]:\n",
    "                return tid\n",
    "\n",
    "    anchor_tid = None\n",
    "\n",
    "    for objs in seg_stream:\n",
    "        if anchor_tid is None:\n",
    "            anchor_tid = find_anchor(objs)\n",
    "\n",
    "        yield anchor_tid\n",
    "\n",
    "\n",
    "def create_metric_depth_stream(depth_stream: DepthStream, seg_stream: SegStream,\n",
    "                               *, anchor_class: int, anchor_pos: tuple[int, int], anchor_dist: float) -> DepthStream:\n",
    "    seg_stream, seg_stream2 = tee(seg_stream)\n",
    "\n",
    "    anchor_stream = create_anchor_stream(\n",
    "        seg_stream2, anchor_class=anchor_class, anchor_pos=anchor_pos)\n",
    "\n",
    "    coeff = None\n",
    "\n",
    "    for depth, objs, anchor in zip(depth_stream, seg_stream, anchor_stream):\n",
    "        if anchor is None:\n",
    "            yield None\n",
    "\n",
    "        # update coeff\n",
    "        if anchor in objs:\n",
    "            avg_dist = np.mean(depth[objs[anchor].mask])\n",
    "            coeff = anchor_dist / avg_dist\n",
    "\n",
    "        yield coeff * depth\n",
    "\n",
    "\n",
    "def create_speed_stream(metric_depth_stream: DepthStream, seg_stream: SegStream, *, fps: int):\n",
    "    objs = {}\n",
    "\n",
    "    for metric_depth, seg_objs in zip(metric_depth_stream, seg_stream):\n",
    "        if metric_depth is None:\n",
    "            yield None\n",
    "\n",
    "        height, width = metric_depth.shape\n",
    "\n",
    "        speeds = {}\n",
    "\n",
    "        for tid, seg_obj in seg_objs.items():\n",
    "            dir = get_pixel_dir_2d(\n",
    "                seg_obj.cx, width, hfov, seg_obj.cy, height, vfov)\n",
    "            avg_dist = np.mean(metric_depth[seg_obj.mask])\n",
    "            pos = avg_dist * dir\n",
    "\n",
    "            if tid not in objs:\n",
    "                objs[tid] = ExpFilter(0.2)\n",
    "\n",
    "            prev_smooth_pos = objs[tid].get()\n",
    "            objs[tid].push(pos)\n",
    "            new_smooth_pos = objs[tid].get()\n",
    "\n",
    "            if prev_smooth_pos is not None:\n",
    "                speeds[tid] = np.linalg.norm(\n",
    "                    new_smooth_pos - prev_smooth_pos) * fps\n",
    "\n",
    "        yield speeds\n",
    "\n",
    "\n",
    "anchor_class = 0\n",
    "anchor_pos = (320, 190)\n",
    "anchor_dist = 5\n",
    "\n",
    "video_stream, frames, fps = create_video_stream(\n",
    "    source_path, proc_width, proc_height)\n",
    "video_streams = tee(video_stream, 3)\n",
    "seg_streams = tee(create_yolo_stream(video_streams[0]), 3)\n",
    "depth_stream = create_vda_stream(video_streams[1], fps, cache=source_path)\n",
    "metric_depth_stream = create_metric_depth_stream(\n",
    "    depth_stream, seg_streams[0], anchor_class=anchor_class, anchor_pos=anchor_pos, anchor_dist=anchor_dist)\n",
    "speed_stream = create_speed_stream(\n",
    "    metric_depth_stream, seg_streams[1], fps=fps)\n",
    "\n",
    "vis_frames = []\n",
    "for frame, seg_objs, speeds in tqdm(zip(video_streams[2], seg_streams[2], speed_stream), total=frames):\n",
    "    overlays = [np.zeros(frame.shape) for _ in range(2)]\n",
    "\n",
    "    for tid, obj in seg_objs.items():\n",
    "        if obj.cls == 0:\n",
    "            overlays[0][obj.mask == 1] = np.array(colors(tid, True))\n",
    "            if tid in speeds:\n",
    "                cv2.putText(overlays[1], fmt_number(\n",
    "                    speeds[tid]), (obj.cx, obj.cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    ws = np.array([2, 1, 1])\n",
    "    ws = ws / sum(ws)\n",
    "\n",
    "    vis_frame = ws[0] * frame + ws[1] * overlays[0] + ws[2] * overlays[1]\n",
    "    vis_frames.append(vis_frame)\n",
    "\n",
    "display_video(vis_frames, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06470fbe-71a4-49d1-b85b-0242d57d7c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated parameters (Pred):\n",
      "Roll:  -1.2° (± 1.7)°\n",
      "Pitch: 1.1° (± 3.3)°\n",
      "vFoV:  67.2° (± 13.0)°\n",
      "Focal: 481.5 px (± 85.4 px)\n"
     ]
    }
   ],
   "source": [
    "from geocalib import GeoCalib\n",
    "from geocalib.utils import deg2rad, print_calibration\n",
    "model = GeoCalib(weights=\"pinhole\").to(DEVICE)\n",
    "\n",
    "video_stream, _, _ = create_video_stream(\n",
    "    \"./sources/test3.mp4\", proc_width, proc_height)\n",
    "frames = []\n",
    "for i, frame in enumerate(video_stream):\n",
    "    if i > 10:\n",
    "        break\n",
    "    frames.append(np.swapaxes(frame, 0, 2))\n",
    "    # frames.append()\n",
    "\n",
    "frames = (torch.tensor(frames).float() / 255).to(DEVICE)\n",
    "\n",
    "print_calibration(model.calibrate(frames[0]))\n",
    "# print(vfov / math.pi * 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58538dbf-9374-4a29-a51e-0fd1a3342111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vda-detector-kernel",
   "language": "python",
   "name": "vda-detector-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
